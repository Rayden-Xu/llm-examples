{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCh9BTedHJK1"
      },
      "source": [
        "![pageindex_banner](https://pageindex.ai/static/images/pageindex_banner.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD0hb4TFHWTt"
      },
      "source": [
        "<p align=\"center\"><i>Reasoning-based RAG&nbsp; ‚úß &nbsp;No Vector DB&nbsp; ‚úß &nbsp;No Chunking&nbsp; ‚úß &nbsp;Human-like Retrieval</i></p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <a href=\"https://vectify.ai\">üè† Homepage</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://dash.pageindex.ai\">üñ•Ô∏è Dashboard</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://docs.pageindex.ai/quickstart\">üìö API Docs</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://github.com/VectifyAI/PageIndex\">üì¶ GitHub</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://discord.com/invite/VuXuf29EUj\">üí¨ Discord</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://ii2abc2jejf.typeform.com/to/tK3AXl8T\">‚úâÔ∏è Contact</a>&nbsp;\n",
        "</p>\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "[![Star us on GitHub](https://img.shields.io/github/stars/VectifyAI/PageIndex?style=for-the-badge&logo=github&label=‚≠êÔ∏è%20Star%20Us)](https://github.com/VectifyAI/PageIndex) &nbsp;&nbsp; [![Follow us on X](https://img.shields.io/badge/Follow%20Us-000000?style=for-the-badge&logo=x&logoColor=white)](https://twitter.com/VectifyAI)\n",
        "\n",
        "</div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebvn5qfpcG1K"
      },
      "source": [
        "# Simple Vectorless RAG with PageIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_IHlCN5rHz5"
      },
      "source": [
        "## PageIndex Introduction\n",
        "PageIndex is a new **reasoning-based**, **vectorless RAG** framework that performs retrieval in two steps:  \n",
        "1. Generate a tree structure index of documents  \n",
        "2. Perform reasoning-based retrieval through tree search  \n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://docs.pageindex.ai/images/cookbook/vectorless-rag.png\" width=\"70%\">\n",
        "</div>\n",
        "\n",
        "Compared to traditional vector-based RAG, PageIndex features:\n",
        "- **No Vectors Needed**: Uses document structure and LLM reasoning for retrieval.\n",
        "- **No Chunking Needed**: Documents are organized into natural sections rather than artificial chunks.\n",
        "- **Human-like Retrieval**: Simulates how human experts navigate and extract knowledge from complex documents.\n",
        "- **Transparent Retrieval Process**: Retrieval based on reasoning ‚Äî say goodbye to approximate semantic search (\"vibe retrieval\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhdRxT-ArHz5"
      },
      "source": [
        "## üìù Notebook Overview\n",
        "\n",
        "This notebook demonstrates a simple, minimal example of **vectorless RAG** with PageIndex. You will learn how to:\n",
        "- [x] Build a PageIndex tree structure of a document\n",
        "- [x] Perform reasoning-based retrieval with tree search\n",
        "- [x] Generate answers based on the retrieved context\n",
        "\n",
        "> ‚ö° Note: This is a **minimal example** to illustrate PageIndex's core philosophy and idea, not its full capabilities. More advanced examples are coming soon.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ziuTbbWcG1L"
      },
      "source": [
        "## Step 0: Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edTfrizMFK4c"
      },
      "source": [
        "#### 0.1 Install PageIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "LaoB58wQFNDh"
      },
      "outputs": [],
      "source": [
        "%pip install -q --upgrade pageindex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVEWzPKGcG1M"
      },
      "source": [
        "#### 0.2 Setup PageIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "StvqfcK4cG1M"
      },
      "outputs": [],
      "source": [
        "from pageindex import PageIndexClient\n",
        "import pageindex.utils as utils\n",
        "\n",
        "# Get your PageIndex API key from https://dash.pageindex.ai/api-keys\n",
        "PAGEINDEX_API_KEY = \"25e12aac29db4cbdb117670f58a44ecb\"\n",
        "pi_client = PageIndexClient(api_key=PAGEINDEX_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwrtT2DjrHz6"
      },
      "source": [
        "#### 0.3 Setup LLM\n",
        "\n",
        "Choose your preferred LLM for reasoning-based retrieval. In this example, we use OpenAI‚Äôs GPT-4.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E0GgCkWFrHz6"
      },
      "outputs": [],
      "source": [
        "# import openai\n",
        "# OPENAI_API_KEY = \"\"\n",
        "\n",
        "# async def call_llm(prompt, model=\"gpt-5.2\", temperature=0):\n",
        "#     client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
        "#     response = await client.chat.completions.create(\n",
        "#         model=model,\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "#         temperature=temperature\n",
        "#     )\n",
        "#     return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-generativeai"
      ],
      "metadata": {
        "id": "ImXcxJEfFskf",
        "outputId": "4389a5a2-e1fd-4985-876c-a54a7e9b704b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.188.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.47.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.2)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U google-genai"
      ],
      "metadata": {
        "id": "kjbV8zU0F69x",
        "outputId": "09e07da7-7949-45ed-b454-ad278ad9fec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m721.9/721.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "# os.environ[\"GEMINI_API_KEY\"] = \"xxxxxx\"\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n",
        "_client = genai.Client()\n",
        "\n",
        "def _call_gemini_sync(prompt: str, model: str, temperature: float) -> str:\n",
        "    response = _client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=prompt,\n",
        "        config={\n",
        "            \"temperature\": temperature,\n",
        "        },\n",
        "    )\n",
        "    if not response.text:\n",
        "        raise RuntimeError(\"Gemini returned empty response\")\n",
        "    return response.text.strip()\n",
        "\n",
        "async def call_llm(\n",
        "    prompt: str,\n",
        "    model: str = \"gemini-3-flash-preview\",\n",
        "    temperature: float = 0,\n",
        ") -> str:\n",
        "    loop = asyncio.get_running_loop()\n",
        "    return await loop.run_in_executor(\n",
        "        None, _call_gemini_sync, prompt, model, temperature\n",
        "    )\n"
      ],
      "metadata": {
        "id": "I4dR1JyNFuHl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heGtIMOVcG1N"
      },
      "source": [
        "## Step 1: PageIndex Tree Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzd1VWjwMUJL"
      },
      "source": [
        "#### 1.1 Submit a document for generating PageIndex tree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, requests"
      ],
      "metadata": {
        "id": "mDk4Dk1SyRIq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_url = \"https://arxiv.org/pdf/2507.17061.pdf\"\n",
        "pdf_path = os.path.join(\"../data\", pdf_url.split('/')[-1])\n",
        "os.makedirs(os.path.dirname(pdf_path), exist_ok=True)"
      ],
      "metadata": {
        "id": "_kXi_vneyOE1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_path(url: str, save_dir: str, ext: str) -> str:\n",
        "    import os\n",
        "\n",
        "    name = url.split(\"/\")[-1]\n",
        "    if not name.endswith(ext):\n",
        "        name += ext\n",
        "\n",
        "    path = os.path.join(save_dir, name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    return path"
      ],
      "metadata": {
        "id": "cs1POX5j1gs3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = safe_path(pdf_url, \"../data\", \".pdf\")"
      ],
      "metadata": {
        "id": "06tDS4Yn1iAh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(pdf_url)\n",
        "with open(path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "print(f\"Downloaded {pdf_url}\")"
      ],
      "metadata": {
        "id": "YUALI2k1yUtg",
        "outputId": "f9d5bf74-0b01-458f-8953-8525d2e89c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded https://arxiv.org/pdf/2507.17061.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.headers.get(\"Content-Type\"))"
      ],
      "metadata": {
        "id": "H6mvhmoa0RC9",
        "outputId": "00de3f26-8774-433f-a2c9-2a4232d7dac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "application/pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_id = pi_client.submit_document(pdf_path)[\"doc_id\"]\n",
        "print('Document Submitted:', doc_id)"
      ],
      "metadata": {
        "id": "Dt5jHPjhyWzW",
        "outputId": "bbcff32d-ae4e-4683-e19e-75776eecc4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PageIndexAPIError",
          "evalue": "Failed to submit document: {\"detail\":\"Only PDF files are supported.\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPageIndexAPIError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1513881009.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"doc_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Document Submitted:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pageindex/client.py\u001b[0m in \u001b[0;36msubmit_document\u001b[0;34m(self, file_path, mode)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPageIndexAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to submit document: {response.text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPageIndexAPIError\u001b[0m: Failed to submit document: {\"detail\":\"Only PDF files are supported.\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "f6--eZPLcG1N"
      },
      "outputs": [],
      "source": [
        "# import os, requests\n",
        "\n",
        "# # You can also use our GitHub repo to generate PageIndex tree\n",
        "# # https://github.com/VectifyAI/PageIndex\n",
        "\n",
        "# pdf_url = \"https://arxiv.org/pdf/2507.17061\"\n",
        "# pdf_path = os.path.join(\"../data\", pdf_url.split('/')[-1])\n",
        "# os.makedirs(os.path.dirname(pdf_path), exist_ok=True)\n",
        "\n",
        "# response = requests.get(pdf_url)\n",
        "# with open(pdf_path, \"wb\") as f:\n",
        "#     f.write(response.content)\n",
        "# print(f\"Downloaded {pdf_url}\")\n",
        "\n",
        "# doc_id = pi_client.submit_document(pdf_path)[\"doc_id\"]\n",
        "# print('Document Submitted:', doc_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Hrh0azcG1N"
      },
      "source": [
        "#### 1.2 Get the generated PageIndex tree structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Q1g6vrcG1O",
        "outputId": "26bd65e2-8b90-4ff9-e08d-1b2e21c0dfdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplified Tree Structure of the Document:\n",
            "[{'title': 'Parallelism Meets Adaptiveness: Scalable...',\n",
            "  'node_id': '0000',\n",
            "  'prefix_summary': '# Parallelism Meets Adaptiveness: Scalab...',\n",
            "  'nodes': [{'title': 'Abstract',\n",
            "             'node_id': '0001',\n",
            "             'summary': 'This paper introduces a novel multi-agen...'},\n",
            "            {'title': '1 Introduction',\n",
            "             'node_id': '0002',\n",
            "             'summary': 'This text introduces a new framework for...'},\n",
            "            {'title': '2 Related Work',\n",
            "             'node_id': '0003',\n",
            "             'summary': 'This text reviews related work in multi-...'},\n",
            "            {'title': '3 Problem Statement and Motivating Use C...',\n",
            "             'node_id': '0004',\n",
            "             'summary': 'The text discusses the limitations of cu...'},\n",
            "            {'title': '4 Core Innovations in Adaptive Coordinat...',\n",
            "             'node_id': '0005',\n",
            "             'summary': 'The text discusses the inadequacy of sta...'},\n",
            "            {'title': '5 System Architecture for Financial Docu...',\n",
            "             'node_id': '0006',\n",
            "             'prefix_summary': 'The text describes a modular multi-agent...',\n",
            "             'nodes': [{'title': '5.1 Parallel Execution and Selection Mec...',\n",
            "                        'node_id': '0007',\n",
            "                        'summary': '### 5.1 Parallel Execution and Selection...'},\n",
            "                       {'title': '5.2 Scoring Function Definition',\n",
            "                        'node_id': '0008',\n",
            "                        'summary': 'The text defines a hierarchical scoring ...'},\n",
            "                       {'title': '5.3 Interaction Flow',\n",
            "                        'node_id': '0009',\n",
            "                        'summary': '### 5.3 Interaction Flow\\n\\nAt runtime, th...'},\n",
            "                       {'title': '5.4 Modularity and Extensibility',\n",
            "                        'node_id': '0010',\n",
            "                        'summary': '### 5.4 Modularity and Extensibility\\n\\nTh...'}]},\n",
            "            {'title': '6 Case Study: Adaptive Coordination for ...',\n",
            "             'node_id': '0011',\n",
            "             'prefix_summary': 'This document presents a case study eval...',\n",
            "             'nodes': [{'title': '6.1 Example Prompt and Comparative Outpu...',\n",
            "                        'node_id': '0012',\n",
            "                        'summary': '### 6.1 Example Prompt and Comparative O...'},\n",
            "                       {'title': '6.2 Pseudocode of Execution Flow',\n",
            "                        'node_id': '0013',\n",
            "                        'summary': '### 6.2 Pseudocode of Execution Flow\\n\\nTh...'},\n",
            "                       {'title': '6.3 Ablation Study',\n",
            "                        'node_id': '0014',\n",
            "                        'summary': '### 6.3 Ablation Study\\n\\nWe ran an ablati...'},\n",
            "                       {'title': '6.4 Key Findings',\n",
            "                        'node_id': '0015',\n",
            "                        'summary': 'The text details key findings from finan...'}]},\n",
            "            {'title': '7 Discussion',\n",
            "             'node_id': '0016',\n",
            "             'summary': 'The discussion highlights the advantages...'},\n",
            "            {'title': '8 Conclusion and Future Work',\n",
            "             'node_id': '0017',\n",
            "             'summary': 'This text concludes by presenting an ada...'},\n",
            "            {'title': 'References',\n",
            "             'node_id': '0018',\n",
            "             'summary': 'This text provides a list of references,...'}]}]\n"
          ]
        }
      ],
      "source": [
        "if pi_client.is_retrieval_ready(doc_id):\n",
        "    tree = pi_client.get_tree(doc_id, node_summary=True)['result']\n",
        "    print('Simplified Tree Structure of the Document:')\n",
        "    utils.print_tree(tree)\n",
        "else:\n",
        "    print(\"Processing document, please try again later...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USoCLOiQcG1O"
      },
      "source": [
        "## Step 2: Reasoning-Based Retrieval with Tree Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaJijGMVrHz7"
      },
      "source": [
        "#### 2.1 Use LLM for tree search and identify nodes that might contain relevant context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "LLHNJAtTcG1O"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "query = \"What are the conclusions in this document?\"\n",
        "\n",
        "tree_without_text = utils.remove_fields(tree.copy(), fields=['text'])\n",
        "\n",
        "search_prompt = f\"\"\"\n",
        "You are given a question and a tree structure of a document.\n",
        "Each node contains a node id, node title, and a corresponding summary.\n",
        "Your task is to find all nodes that are likely to contain the answer to the question.\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Document tree structure:\n",
        "{json.dumps(tree_without_text, indent=2)}\n",
        "\n",
        "Please reply in the following JSON format:\n",
        "{{\n",
        "    \"thinking\": \"<Your thinking process on which nodes are relevant to the question>\",\n",
        "    \"node_list\": [\"node_id_1\", \"node_id_2\", ..., \"node_id_n\"]\n",
        "}}\n",
        "Directly return the final JSON structure. Do not output anything else.\n",
        "\"\"\"\n",
        "\n",
        "tree_search_result = await call_llm(search_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dB1CDRKrHz7"
      },
      "source": [
        "#### 2.2 Print retrieved nodes and reasoning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8DVUOuAen5u",
        "outputId": "d510654b-da69-434f-c05f-152e50540090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reasoning Process:\n",
            "To find the conclusions of the document, I looked for sections that summarize the results, findings,\n",
            "and final thoughts. The 'Abstract' (0001) provides a high-level summary of the outcomes. 'Key\n",
            "Findings' (0015) details the specific results from the experiments. The 'Discussion' (0016)\n",
            "interprets these results and their implications. Finally, 'Conclusion and Future Work' (0017)\n",
            "explicitly states the final conclusions and future directions. The 'Case Study' (0011) also contains\n",
            "summary data about the system's performance which forms the basis of the conclusions.\n",
            "\n",
            "Retrieved Nodes:\n",
            "Node ID: 0001\t Page: 1\t Title: Abstract\n",
            "Node ID: 0011\t Page: 4\t Title: 6 Case Study: Adaptive Coordination for 10-K Analysis\n",
            "Node ID: 0015\t Page: 6\t Title: 6.4 Key Findings\n",
            "Node ID: 0016\t Page: 6\t Title: 7 Discussion\n",
            "Node ID: 0017\t Page: 7\t Title: 8 Conclusion and Future Work\n"
          ]
        }
      ],
      "source": [
        "node_map = utils.create_node_mapping(tree)\n",
        "tree_search_result_json = json.loads(tree_search_result)\n",
        "\n",
        "print('Reasoning Process:')\n",
        "utils.print_wrapped(tree_search_result_json['thinking'])\n",
        "\n",
        "print('\\nRetrieved Nodes:')\n",
        "for node_id in tree_search_result_json[\"node_list\"]:\n",
        "    node = node_map[node_id]\n",
        "    print(f\"Node ID: {node['node_id']}\\t Page: {node['page_index']}\\t Title: {node['title']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10wOZDG_cG1O"
      },
      "source": [
        "## Step 3: Answer Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cEHk40orHz7"
      },
      "source": [
        "#### 3.1 Extract relevant context from retrieved nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7UCBnXlcG1O",
        "outputId": "49c36e46-f427-4ac9-ae32-35c594dc5358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Context:\n",
            "\n",
            "## Abstract\n",
            "\n",
            "Large language model (LLM) agents have shown increasing promise for collaborative task completion.\n",
            "However, existing multi-agent frameworks often rely on static workflows, fixed roles, and limited\n",
            "inter-agent communication, reducing their effectiveness in open-ended, high-complexity domains. This\n",
            "paper present a multi-agent coordination framework that improves the accuracy of Large Language\n",
            "Models (LLMs) in complex financial document analysis. Unlike existing frameworks that rely on static\n",
            "routing or linear workflows, our approach introduces Parallel Agent Evaluation, a mechanism where\n",
            "multiple agents compete on high-ambiguity subtasks. A centralized evaluator scores these parallel\n",
            "outputs based on factuality and coherence to select the optimal result. We evaluate this\n",
            "architecture on SEC 10-K filings, demonstrating a 27% improvement in compliance accuracy and a 74%\n",
            "reduction in revision rates compared to standard static baselines. These results validate that\n",
            "structured co...\n"
          ]
        }
      ],
      "source": [
        "node_list = json.loads(tree_search_result)[\"node_list\"]\n",
        "relevant_content = \"\\n\\n\".join(node_map[node_id][\"text\"] for node_id in node_list)\n",
        "\n",
        "print('Retrieved Context:\\n')\n",
        "utils.print_wrapped(relevant_content[:1000] + '...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QAwUU1zrHz7"
      },
      "source": [
        "#### 3.2 Generate answer based on retrieved context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcp_PhHzcG1O",
        "outputId": "4a05aad6-19a9-453c-ee20-a0e9b9fb0d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Answer:\n",
            "\n",
            "Based on the provided document, here are the conclusions reached by the authors, followed by an AI\n",
            "expert‚Äôs perspective on the framework.\n",
            "\n",
            "### Part 1: Conclusions from the Document\n",
            "\n",
            "The authors conclude that moving away from static, linear multi-agent workflows toward an **adaptive\n",
            "and competitive coordination framework** significantly improves the performance of LLMs in complex,\n",
            "high-stakes domains like financial analysis. Their specific conclusions include:\n",
            "\n",
            "1.  **Superior Performance Metrics:** The \"Full System\" (incorporating parallel evaluation) achieved\n",
            "a **0.94 compliance accuracy** and **0.92 factual coverage**, representing a **27% improvement** in\n",
            "accuracy over static baselines.\n",
            "2.  **Reduction in Errors:** The framework effectively severed the \"cascade of errors\" typical in\n",
            "LLM chains, resulting in a **74% reduction in revision rates** and a **73% reduction in redundancy\n",
            "penalties**.\n",
            "3.  **Value of Structured Competition:** The authors conclude that redundancy is a feature, not a\n",
            "bug. By having multiple agents compete on ambiguous tasks and using a centralized evaluator to\n",
            "select the best output, the system becomes more resilient to \"hallucinations\" and interpretive\n",
            "uncertainty.\n",
            "4.  **Efficiency through Specialization:** Dynamic routing allowed the system to be **14% faster**\n",
            "than static assignments by autonomously offloading technical tasks to specialized agents (e.g.,\n",
            "legal parsing vs. narrative summarization).\n",
            "5.  **Inadequacy of Static Pipelines:** The study concludes that static pipelines are insufficient\n",
            "for real-world financial NLP, which requires systems that can adapt to regulatory complexity and\n",
            "reconcile conflicting information.\n",
            "\n",
            "---\n",
            "\n",
            "### Part 2: AI Expert Analysis of the Framework\n",
            "\n",
            "As an AI expert, I find this framework‚Äîspecifically the **Parallel Agent Evaluation** mechanism‚Äîto\n",
            "be a sophisticated evolution in agentic design. Here is my assessment:\n",
            "\n",
            "#### 1. Addressing the \"Stochastic Nature\" of LLMs\n",
            "The biggest hurdle in using LLMs for financial or legal work is their non-deterministic nature. This\n",
            "framework treats LLM outputs as \"candidates\" rather than \"answers.\" By implementing a **\"Best-of-N\"\n",
            "approach at the agent level**, the system mimics a high-functioning human office where a manager\n",
            "(the Evaluator) reviews multiple drafts from different analysts to find the most accurate one.\n",
            "\n",
            "#### 2. The \"Evaluator\" as the Critical Bottleneck\n",
            "While the framework is robust, the **Evaluator Agent** is a single point of failure. If the scoring\n",
            "function or the Evaluator LLM has a bias or lacks the specific domain expertise to distinguish\n",
            "between two highly technical financial interpretations, the entire system's accuracy collapses. The\n",
            "authors correctly identify this in their limitations, noting that the evaluator could introduce\n",
            "systematic bias.\n",
            "\n",
            "#### 3. The Cost-Latency Trade-off\n",
            "From an engineering perspective, this framework is \"expensive.\" Running parallel agents for a single\n",
            "subtask doubles or triples the token consumption and increases latency. However, in the context of\n",
            "**SEC 10-K filings**, where a single factual error can have million-dollar regulatory consequences,\n",
            "the trade-off of higher inference cost for a 27% accuracy gain is an easy business decision to\n",
            "justify.\n",
            "\n",
            "#### 4. Evolution from DAGs to Dynamic Graphs\n",
            "Most current industry frameworks (like basic LangChain or early AutoGPT) rely on Directed Acyclic\n",
            "Graphs (DAGs). This paper pushes the field toward **Dynamic Orchestration**. The use of a \"Feedback\n",
            "Bus\" and \"Shared Memory\" allows the system to self-correct in real-time, which is essential for\n",
            "long-context documents where an error on page 5 might contradict a figure on page 50.\n",
            "\n",
            "#### 5. Final Verdict\n",
            "This is a **highly practical and necessary architecture** for \"High-Stakes NLP.\" It moves the\n",
            "conversation from \"how do we make the model smarter?\" to \"how do we build a system that manages the\n",
            "model's inherent limitations?\" Future iterations that replace the heuristic-based routing with\n",
            "**learned policies** (as the authors suggest) will likely become the gold standard for enterprise-\n",
            "grade AI agents.\n"
          ]
        }
      ],
      "source": [
        "answer_prompt = f\"\"\"\n",
        "Answer the question based on the context:\n",
        "\n",
        "Question: {query}\n",
        "Context: {relevant_content}\n",
        "\n",
        "You are the AI expert, how do you think this framework?\n",
        "\"\"\"\n",
        "\n",
        "print('Generated Answer:\\n')\n",
        "answer = await call_llm(answer_prompt)\n",
        "utils.print_wrapped(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1kaGD3GcG1O"
      },
      "source": [
        "---\n",
        "\n",
        "## üéØ What's Next\n",
        "\n",
        "This notebook has demonstrated a **basic**, **minimal** example of **reasoning-based**, **vectorless** RAG with PageIndex. The workflow illustrates the core idea:\n",
        "> *Generating a hierarchical tree structure from a document, reasoning over that tree structure, and extracting relevant context, without relying on a vector database or top-k similarity search*.\n",
        "\n",
        "While this notebook highlights a minimal workflow, the PageIndex framework is built to support **far more advanced** use cases. In upcoming tutorials, we will introduce:\n",
        "* **Multi-Node Reasoning with Content Extraction** ‚Äî Scale tree search to extract and select relevant content from multiple nodes.\n",
        "* **Multi-Document Search** ‚Äî Enable reasoning-based navigation across large document collections, extending beyond a single file.\n",
        "* **Efficient Tree Search** ‚Äî Improve tree search efficiency for long documents with a large number of nodes.\n",
        "* **Expert Knowledge Integration and Preference Alignment** ‚Äî Incorporate user preferences or expert insights by adding knowledge directly into the LLM tree search, without the need for fine-tuning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbIV71uDrHz8"
      },
      "source": [
        "## üîé Learn More About PageIndex\n",
        "  <a href=\"https://vectify.ai\">üè† Homepage</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://dash.pageindex.ai\">üñ•Ô∏è Dashboard</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://docs.pageindex.ai/quickstart\">üìö API Docs</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://github.com/VectifyAI/PageIndex\">üì¶ GitHub</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://discord.com/invite/VuXuf29EUj\">üí¨ Discord</a>&nbsp; ‚Ä¢ &nbsp;\n",
        "  <a href=\"https://ii2abc2jejf.typeform.com/to/tK3AXl8T\">‚úâÔ∏è Contact</a>\n",
        "\n",
        "<br>\n",
        "\n",
        "¬© 2025 [Vectify AI](https://vectify.ai)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}